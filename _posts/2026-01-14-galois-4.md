---
layout: post
title:  "Quick Intro to Galois Theory: Part-4"
date:   2026-01-14
categories: [math]
mathjax: true
---
**Link to the previous parts: [Part-1](galois-1.html) [Part-2](galois-2.html) [Part-3](galois-3.html)**

# Field and Field Extensions

So far we have observed that, for solving a polynomial:

1.  We can create a new variable $t$ called the resolvent which is
    expressed entirely using the roots of the polynomial and known
    quantities (like coefficients of the polynomial and roots of unity).

2.  $t$ can be expressed as a root of a polynomial with known
    coefficients. We have been able to solve this polynomial so far in
    the cases that we have explored. Though, this is not always
    guaranteed.

3.  Once we find $t$, we can obtain all the roots using known
    quantities.


## Lagrange Theorem on Resolvents

Suppose $t$ is an expression in terms of the roots and known quantities,
and $u$ is another expression in roots and known quantities. Let us
evaluate all possible values of $t$ and $u$ under the various root
permutations. If it so happens that the permutations that change the
value of $u$ also change the value of $t$, then $u$ can be expressed
using $t$ and other known values.

**Proof**: Let us assume there are $k$ different values that $u$ can
take under the root permutations: $u_1$, $u_2$, $u_3$, $\ldots$, $u_k$.
Let the corresponding values of $t$ be $t_1$, $t_2$, $t_3$, $\ldots$,
$t_k$. Consider the following:

$$u_1 + u_2 + \ldots + u_k$$

$$t_1u_1 + t_2u_2 + \ldots + t_ku_k$$

$$t_1^2u_1 + t_2^2u_2 + \ldots + t_k^2u_k$$

$$t_1^3u_1 + t_2^3u_2 + \ldots + t_k^3u_k$$ $$\vdots$$

$$t_1^{k-1}u_1 + t_2^{k-1}u_2 + \ldots + t_k^{k-1}u_k$$

All these expressions are symmetric in roots and are known quantities.
Hence, $u_1\text{s}$ can be expressed in terms of $t_i^j$:

$$u_1 = \frac{D_1}{D} = \frac{D_1D}{D^2}$$

where D is the Vandermonde
Determinant, $D^2 = \prod (t_i - t_j)^2$. $D^2$ is symmetric in $t_i$
and hence symmetric in roots and is a known quantity. $D_1$ is same as D
but $t_1^j$ is replaced with the value of the $j^{th}$ expression in the
above system of equations. Hence, the numerator is a polynomial in $t_1$
whose coefficients are symmetric polynomials in $t_2$, $t_3$, $\ldots$,
$t_k$, which in turn can be expressed as polynomials in $t_1$. Hence
$u_1$ can be expressed as polynomial in $t_1$ (with coefficients being
known quantities).

If we can find a $t$ such that it takes $n!$ different values under root
permutations, we have got our resolvent. Indeed, such a resolvent can
always be formed using a linear combination of roots. For such a linear
combination to not change under some requires the coefficients to
satisfy elaborate constraints. Finding all such constraints for our
given polynomial and then choosing coefficients that violate this
constraint provides us the resolvent. We have not only proved the
existence of a resolvent, but also a resolvent that is linear in the
roots.

## Field

From now on, we consider all known quantities to come from a "Field\". A
field is closed under the basic algebraic operations like addition,
subtraction, multiplication, and division (of non-zero elements).
However, root operations like square roots, cube roots, etc., are not
supported in a field. We represent our field of known quantities as $K$.
$K$ contains the coefficients of the given polynomial and other rational
numbers. We sometimes also assume it to contain roots of unity.

## Field Extension

Suppose $g(x)$ is a irreducible polynomial with coefficients from $K$.
Let $t$ be a root of $g(x)$. Then, we can introduce a new element $t$ to
the existing field $K$ using an extension. We represent this as $K(t)$.
Since $K \in K(t)$ and $t \in K(t)$, any polynomial in $t$ with
coefficients in $K$ must also be in $K(t)$. We can show that this is
enough to form a new bigger field.

Consider the set of polynomials in some variable with coefficients from
$K$. Two polynomials that have the same remainder on division by $g(x)$
is considered to be equal. Addition, subtraction and multiplication of
two such polynomials would result in another polynomial.

For defining division, we need to first define a way to effectively
invert any $a \in K(t)$ such that $a(x)b(x) = g(x)h(x) + 1$. We can
always find this using Euclid's method of finding GCD of two
polynomials. Since $g(x)$ is irreducible, the GCD of $a, g$ is $1$.
Hence all elements of $K(t)$ can be inverted and we can define division
as multiplication by the inverse.

## Splitting Field

The field extension $K(r_1, r_2, \ldots, r_n)$ which contains all the
roots of the polynomial of the polynomial is called the Splitting Field.
Solving a polynomial is equivalent to finding the Splitting Field. From
Lagrange's Theorem on Resolvents, we have shown that there is always a
$t$ such that $K(t) = K(r_1, r_2, \ldots, r_n)$. The resolvent
polynomial $g$ which has coefficients in $K$ and takes $t$ as a root is
easy to find. We start with a polynomial whose roots are $t$ and all its
values under the root permutations. This polynomial has coefficients in
$K$. We factorize this polynomial into irreducible factors. The
irreducible factor that contains $t$ as a root is our resolvent
polynomial $g$.

# Root Permutations

Let us revisit the solution to the quartic using the Lagrange Resolvent
by following the irreducible polynomial containing $t_1$ as a root.

Initially, the resolvent polynomial is the full $24$ degree polynomial.
The only expression in roots that can be evaluated (as a known quantity)
at this point are the ones that remain unchanged by all the $24$
permutations of the roots.

In the next step, we end up knowing the values of $r_1r_2 + r_3r_4$,
$r_1r_3 + r_2r_4$, $r_1r_4 + r_2r_3$. These are not symmetric
polynomials in roots. The root permutations that preserve them are:

1.  $(r_1, r_2, r_3, r_4)$: The identity permutation

2.  $(r_2, r_1, r_4, r_3)$: Flip $(r_1, r_2)$ and Flip $(r_3, r_4)$

3.  $(r_3, r_4, r_1, r_2)$: Flip $(r_1, r_3)$ and Flip $(r_2, r_4)$

4.  $(r_4, r_3, r_2, r_1)$: Flip $(r_1, r_4)$ and Flip $(r_2, r_3)$

At this point, the resolvent polynomial is $(x^2-t_1^2)(x^2+t_2^2)$.
These permutations take $t_1$ to the other roots of the resolvent
polynomial: $t_1$, $-t_1$, $it_2$, $-it_2$. The only expressions in
roots that we can evaluate at this stage happens to be polynomials in
roots that remain unchanged by these permutations. For example, we can
evaluate $(r_1 + r_2)(r_3 + r_4)$.

In the next step, we end up knowing the values of $r_1r_2$, $r_3r_4$.
The root permutations that preserve them, among the permutations listed
above are:

1.  $(r_1, r_2, r_3, r_4)$: The identity permutation

2.  $(r_2, r_1, r_4, r_3)$: Flip $(r_1, r_2)$ and Flip $(r_3, r_4)$

At this point, the resolvent polynomial is $(x^2-t_1^2)$. These
permutations take $t_1$ to the other roots of the resolvent polynomial:
$t_1$, $-t_1$. The only expressions in roots that we can evaluate at
this stage happens to be polynomials in roots that remain unchanged by
these permutations. For example, we can evaluate $(r_1 + r_2)$ and
$(r_3 + r_4)$.

We notice the following pattern:

1.  Polynomial expressions in roots that can be evaluated as known
    quantities are characterized by a subset of root permutations.

2.  These same permutations map one root of the resolvent polynomial to
    the other roots of the resolvent polynomial.

## Root Permutations

$K(t) = K(r_1,r_2,\ldots,r_n)$. $t$ is a root of $g(x)$. Once we solve
for $t$, we can recover the roots $r_1$, $r_2$, $\ldots$, $r_n$, using a
polynomial in $t$:

$$r_1 = \phi_1(t), r_2 = \phi_2(t), \ldots r_n = \phi_2(t)$$

However, we cannot distinguish one root of $g(x)$ from another. Thus, if
$t'$ is another root of $g(x)$, we could also get a permutation of the
roots $r_1$, $r_2$, $\ldots$, $r_n$ as

$$\phi_1(t'), \phi_2(t'), \ldots \phi_2(t')$$

We can show that this is a permutation of $r_1$, $r_2$, $\ldots$, $r_n$.
$f(\phi_i(x))$ has $t$ as a root. Then, the irreducible polynomial of
$t$: $g(x)$ divides $f(\phi_i(x))$. So, $f(\phi_i(t')) = 0$ establishing
that $\phi_1(t')$, $\phi_2(t')$, $\ldots$, $\phi_2(t')$ are all roots of
$f(x)$.

Further, if $\phi_i(t') = \phi_j(t')$, then the polynomial
$\phi_i(x) - \phi_j(x)$ has a root $t'$. Then $g(x)$ $|$
$\phi_i(x) - \phi_j(x)$ and $t$ is also a root of
$\phi_i(x) - \phi_j(x)$ implying that $\phi_i(t) =  \phi_j(t)$, which is
not possible.

Thus, $\phi_1(t')$, $\phi_2(t')$, $\ldots$, $\phi_2(t')$ is a
rearrangement of $r_1$, $r_2$, $\ldots$, $r_n$. If we were to somehow
know $t$, and then find the roots $r_i$ using $t$, we will not be able
to distinguish between these permutations. Let us call these
permutations as "**Allowed Permutations**\".

## Polynomial Expressions in Roots that can be evaluated

Consider any polynomial expression in roots:
$\psi(r_1, r_2,\ldots,r_n)$. We know that

$$\psi(r_1, r_2,\ldots,r_n) = \psi(\phi_1(t), \phi_2(t), \ldots, \phi_n(t)) \in K(t)$$

since it is a polynomial in $t$. Suppose that we can evaluate this
expression, and assign it a known value. Then,
$\psi(r_1, r_2,\ldots,r_n) = c \in K$. This implies that $t$ is a root
of $\psi(\phi_1(x), \phi_2(x), \ldots, \phi_n(x)) - c =0$. Again, by the
same logic as before, any $t'$ is also a root of
$\psi(\phi_1(x), \phi_2(x), \ldots, \phi_n(x)) - c = 0$. This shows that
if we can evaluate any polynomial expression in roots, then it is
invariant under all the allowed root permutations.

The converse of this statement is also true. If we have an expression
that is invariant under all the allowed root permutations, then it can
be assigned a value from $K$. Suppose $\psi$ is invariant to all the
allowed permutations. Then,

$$\psi(\phi_1(t), \phi_2(t), \ldots, \phi_n(t)) = \psi(\phi_1(t), \phi_2(t), \ldots, \phi_n(t))$$

$$\psi(\phi_1(t), \phi_2(t), \ldots, \phi_n(t)) = \psi(\phi_1(t'), \phi_2(t'), \ldots, \phi_n(t'))$$

$$\psi(\phi_1(t), \phi_2(t), \ldots, \phi_n(t)) = \psi(\phi_1(t''), \phi_2(t''), \ldots, \phi_n(t''))$$

$$\vdots$$

$$\psi(\phi_1(t), \phi_2(t), \ldots, \phi_n(t)) = \psi(\phi_1(t^{(k)}), \phi_2(t^{(k)}), \ldots, \phi_n(t^{(k)}))$$

Adding them all up, we get:

$$\psi(\phi_1(t), \phi_2(t), \ldots, \phi_n(t)) = \frac{1}{k+1} \sum_{i=0}^{k} \psi(\phi_1(t^{(i)}), \phi_2(t^{(i)}), \ldots, \phi_n(t^{(i)}))$$

The right side of this expression is symmetric in the roots of $g(x)$.
Hence, it is a known quantity.

Thus the only expressions that can be evaluated as a known quantity are
those that are invariant under the allowed root permutations.

# Group of Root Permutations

So far we have found that:

1.  $K(t) = K(r_1, r_2, \ldots, r_n)$. Solving for the roots of the
    polynomial $f(x)$ is equivalent to solving for the resolvent
    polynomial $g(x)$. $t$ is a polynomial in the roots:
    $t = \psi(r_1, r_2, \ldots, r_n)$ and the roots $r_i$ can be
    expressed as a polynomial in $t$: $r_i = \phi_i(t)$. $g(x)$ is the
    polynomial whose roots are $t$ and its variants under all the root
    permutations of $r_i\text{s}$. If $g$ can be factorized, we take the
    irreducible factor containing the root $t$ and call it $g$.

2.  At this point, if we were to somehow solve $g(x)$ and get $t$, it
    could be any one of the roots $t'$ of $g(x)$. If we then were to
    recover the roots of $f(x)$ using
    $(\phi_1(t'),\phi_2(t'),\ldots,\phi_n(t'))$, it would be a
    permutation of $r_i\text{s}$.

3.  A polynomial in $r_i\text{s}$ can be evaluated to a known quantity in $K$
    if and only if it is invariant to these same permutations.

Since $t$ can be expressed as polynomials in roots $r_i$:
$t = \psi(r_1, r_2, \ldots, r_n)$, we would like to know what effect
does the allowed permutations have on $t$.

## Extending Root Permutations to Automorphisms

In the last section, we looked at each element of the extended field as
an element of $K(t)$. However, these can also be looked at as elements
of $K(r_1,r_2,\ldots,r_n)$. Given any allowed permutation $\sigma$, we
can apply it on the entire field, since any element of the field can be
expressed as a polynomial in $r_1,r_2,\ldots,r_n$ with coefficients from
$K$. By defining $\sigma(k) = k$ for all $k \in K$ and
$\sigma(r_i) = \phi_i(t')$. For any element $u \in K(t)$, we can define:

$$\sigma(u) = \sigma(\psi(r_1,r_2,\ldots,r_n)) = \psi(\sigma(r_1),\sigma(r_2),\ldots,\sigma(r_n))$$

This is equivalent to saying:

$$\sigma(\psi(\phi_1(t),\phi_2(t),\ldots,\phi_n(t))) = \psi(\phi_1(t'),\phi_2(t'),\ldots,\phi_n(t'))$$

For this definition to be well-defined, we need that, whenever we have
two different representations of $u$, $\sigma(u)$ defined using either
of those representations is consistent with the other. If:

$$u = \psi_1(r_1,r_2,\ldots,r_n)=\psi_2(r_1,r_2,\ldots,r_n)$$

Then,

$$\psi_1(r_1,r_2,\ldots,r_n) - \psi_2(r_1,r_2,\ldots,r_n) = 0$$

$$\psi_1(\phi_1(t),\phi_2(t),\ldots,\phi_n(t)) - \psi_2(\phi_1(t),\phi_2(t),\ldots,\phi_n(t)) = 0$$

This can be seen as a polynomial with coefficients in $K$ with a root
$t$. It immediately follows that $t'$ is also a root of the same
polynomial:

$$\psi_1(\phi_1(t'),\phi_2(t'),\ldots,\phi_n(t')) - \psi_2(\phi_1(t'),\phi_2(t'),\ldots,\phi_n(t')) = 0$$

which is same as saying:

$$\sigma(\psi_1(\phi_1(t),\phi_2(t),\ldots,\phi_n(t))) = \sigma(\psi_2(\phi_1(t),\phi_2(t),\ldots,\phi_n(t)))$$

It is easy to see that the mapping $\sigma$ preserves sums and products:

$$\sigma(x + y) = \sigma(x) + \sigma(y)$$

$$\sigma(xy) = \sigma(x)\sigma(y)$$

where $x, y$ are polynomials of the
form $\psi(r_1,r_2,\ldots,r_n)$. Hence $\sigma$ defined this way is an
automorphism from $K(r_1,r_2,\ldots,r_n)$ to itself.

## Effect on roots of resolvent polynomial

We would like to know how $\sigma$ acts on $t$, $t'$ and other roots of
$g(x)$. To begin with, we can verify that, $\sigma(t) = t'$. If
$t = \psi(r_1, r_2, \ldots, r_n)$:

$$t = \psi(r_1, r_2, \ldots, r_n) = \psi(\phi_1(t), \phi_2(t), \ldots, \phi_n(t))$$

$t$ is a root of
$\psi(\phi_1(x), \phi_2(x), \ldots, \phi_n(x)) - x = 0$. And hence any
other $t'$ is a root of the same polynomial giving:

$$t' = \psi(\phi_1(t'), \phi_2(t'), \ldots, \phi_n(t'))$$

$$t' = \psi(\sigma(r_1), \sigma(r_2), \ldots, \sigma(r_n))$$

This shows that the allowed permutation derived from $t \to t'$ maps $t$
to $t'$. For exploring the effect of $\sigma$ on any root other than $t$
(say $t'$), we know that:

$$g(t') = 0$$

$g(x)$ is a polynomial with
coefficients in $K$, we can apply $\sigma$ on $g(x)$ to get
$\sigma(g(x)) = g(\sigma(x))$. This happens because $\sigma$ leaves any
element of $K$ unchanged. Hence, applying $\sigma$ on both sides:

$$g(\sigma(t')) = 0$$

This shows that $\sigma(t')$ is also a root of
$g(x)$. Thus, the allowed root permutations map one root of $g$ to
another. $\sigma(t) = t'$, $\sigma(t') =t''$ and so on.

## Group

We can use this fact to compose two allowed root permutations on top of
each other to get another allowed root permutation. We can interpret the
first permutation as moving $t \to t'$ and the second one as moving
$t' \to t''$. Since, the permutation $t \to t''$ is also a allowed root
permutation, we know that composition of two allowed permutations gives
another allowed permutation.

A set of permutations that contains the identity permutation and are
closed under compositions is called a Group. The group of allowed root
permutations is called the Galois Group: $\text{Gal}(K(r_1,r_2,\ldots,r_n)/K)$.
The size of the Galois Group = degree of $g(x)$. All possible $n!$
permutations form the permutation group $S_n$. Galois Group is a
subgroup of $S_n$.

## Examples of Galois Groups

For the general polynomial of $n^{th}$ degree, the Galois Group contains
all the $n!$ permutations.

For some special polynomials like the ones for the $p$-th root of unity,
the roots have more algebraic structure in them. The roots are of the
form $\alpha$, $\alpha^2$, $\alpha^3$, $\ldots$, $\alpha^{p-1}$. Any
allowed root permutation is a automorphism that preserves algebraic
structure. Thus defining $\sigma(\alpha) = \alpha^i$ defines the root
permutation for all the other roots, since for any other root
$\alpha^j$, $\sigma(\alpha^j) = \sigma(\alpha)^j = \alpha^{ij}$. In this
way, there are only $p$ possible root permutations:
$\sigma(\alpha) = \alpha^i$ where $i = 1,2,3\ldots,p$.

## Fixed Points

From the previous section, we know that if any polynomial expression in
roots in invariant to all the root permutations, then it must be in $K$.
This can also be stated as: If for some $x \in K(r_1,r_2,\ldots,r_n)$,
$\sigma(x) = x$ for all $\sigma$ from the Galois Group, then $x \in K$.

# Groups and Subgroups

What we know so far:

1.  There are two ways to look at the field containing the roots of
    $f(x)$: $K(r_1, r_2, \ldots, r_n) = K(t)$. If we were to ever solve
    the resolvent polynomial $g(x)$, and try to recover the roots
    $(r_1,r_2,\ldots,r_n)$ of $f(x)$, we would not be able to
    distinguish between the different roots of $g(x)$ or equivalently
    certain permutations of $(r_1,r_2,\ldots,r_n)$. These permutations
    of $(r_1,r_2,\ldots,r_n)$ form a group called the Galois Group.

2.  Any $\sigma \in \text{Gal}(K(r_1,r_2,\ldots,r_n)/K)$, can be extended to
    an Automorphism on $K(r_1,r_2,\ldots,r_n)$ that leaves $K$
    unchanged. Equivalently, any polynomial in $(r_1,r_2,\ldots,r_n)$
    that can be evaluated as a known quantity in $K$ is invariant to the
    permutations in the Galois Group.

3.  The converse is also true. If there is any
    $x \in K(r_1,r_2,\ldots,r_n)$ such that $\sigma(x)=x$ for all
    $x \in \text{Gal}(K(r_1,r_2,\ldots,r_n)/K)$, then $x \in K$.
    Equivalently, if a polynomial in $(r_1,r_2,\ldots,r_n)$ is invariant
    to all permutations in the Galois Group, then, the polynomial can be
    evaluated as a known quantity in $K$.

We know from our experience of solving cubic and quartic equations that
the process of solving the polynomial involves extending the field $K$
with appropriate entity $r$ to enable factorizing $g(x)$ into a
polynomial $h(x)$ of a smaller degree, such that $h(x)$ has $t$ as a
root and is irreducible in $K(r)$. We would like to know how the
$\text{Gal}(K(r_1,r_2,\ldots,r_n)/K(r))$ relates to the 
$\text{Gal}(K(r_1,r_2,\ldots,r_n)/K)$.

Here is an example. For the cubic equation, we start with the resolvent
polynomial which is of degree $6 = 3!$ with (say $t=t_1$):

$$t_1 = r_1 + \omega r_2 + \omega^2 r_3$$

$$t_2 = r_3 + \omega r_1 + \omega^2 r_2$$

$$t_3 = r_2 + \omega r_3 + \omega^2 r_1$$

$$t_4 = r_1 + \omega r_3 + \omega^2 r_2$$

$$t_5 = r_2 + \omega r_1 + \omega^2 r_3$$

$$t_6 = r_3 + \omega r_2 + \omega^2 r_1$$

The irreducible resolvent
polynomial is:

$$g(x) = \prod_{i=1}^{6}(x - t_i)$$

After we are able to extend the field with:

$$
\begin{align*}
t_1^3 = (r_1 + \omega r_2 + \omega^2 r_3)^3 &= r_1^3 + r_2^3 + r_3^3 + 6r_1 r_2 r_3 \\&
+3\omega(r_1^2r_2+r_2^2r_3+r_3^2r_1)\\
&+3\omega^2(r_1r_2^2+r_2r_3^2+r_3r_1^2)\\    
t_4^3 = (r_1 + \omega^2 r_2 + \omega r_3)^3 &= r_1^3 + r_2^3 + r_3^3 + 6r_1 r_2 r_3 \\&
+3\omega^2(r_1^2r_2+r_2^2r_3+r_3^2r_1)\\
&+3\omega(r_1r_2^2+r_2r_3^2+r_3r_1^2)
\end{align*}
$$

We are able to factorize $g(x)$ into the two irreducible
factors $h(x) = h_1(x) = (x^3-t_1^3)$ and $h_2(x) = (x^3-t_4^3)$. The
Galois Group corresponding to $g(x)$ is $S_3$, the entire permutation
group of all $3! = 6$ permutations. For the resolvent polynomial $h(x)$
we have the roots:

$$t_1 = r_1 + \omega r_2 + \omega^2 r_3$$

$$t_2 = r_3 + \omega r_1 + \omega^2 r_2$$

$$t_3 = r_2 + \omega r_3 + \omega^2 r_1$$

The Galois Group corresponding
to $h(x)$ contains $3$ permutations: The permutation of $(r_1,r_2,r_3)$
into one of $\{(r_1,r_2,r_3),(r_3,r_1,r_2),(r_2,r_3,r_1)\}$. These
permutations correspond to $t_1 \to t_1$, $t_1 \to t_2$, and
$t_1 \to t_3$. We observe that these same permutations map
$t_4 \to t_4$, $t_4 \to t_6$, and $t_4 \to t_5$.

## Subgroup

When $g(x)$ can be factorized into a smaller irreducible polynomial
$h(x)$, such that $t$ is a root of $h(x)$, we can define a new Galois
Group corresponding to $\text{Gal}(K(r_1,r_2,\ldots,r_n)/K(r))$. This new
Galois Group maps roots of $h(x)$ to itself. These permutations can then
be extended onto the entire field $K(r_1,r_2,\ldots,r_n)$ such that it
leaves $K(r)$ unchanged.

The factors of $g(x)$ are polynomials with coefficients from $K(r)$.
Suppose $h_2(x)$ is one such factor. Let $\sigma$ be a permutation from
the new Galois Group. Then, $\sigma(h_2(x)) = h_2(\sigma(x))$. Thus
$\sigma$ maps roots of each factor of $g$ onto other roots of the same
factor. In this way, it maps all roots of $g(x)$ to other roots of
$g(x)$. This proves that the Galois Group corresponding to $h(x)$ is a
subgroup of the Galois Group corresponding to $g(x)$.

## Cosets and Size of Subgroup

Let us denote:

$$G := \text{Gal}(K(r_1,r_2,\ldots,r_n)/K)$$

$$H := \text{Gal}(K(r_1,r_2,\ldots,r_n)/K(r))$$

$H$ is a subgroup of $G$. For any $\sigma \notin H$, consider the set of permutations
$\sigma H = \{\sigma h$ $|$ $h \in H\}$. Let $\sigma(t) = t'$. $t'$ is a
root of $g(x)$, but not $h(x)$. Let $t'$ be root of $h_2(x)$. $\sigma H$
consists of permutations that map $t \to t' \to t''$. We know that
permutations in $H$ map roots of $h_2(x)$ to another root of $h_2(x)$.
Thus, $t''$ is also a root of $h_2(x)$. $\sigma H$ can then be
interpreted as permutations that map $t$ to some root $t''$ of $h_2(x)$.

If two permutations of $\sigma H$ map $t$ to the same root of $h_2(x)$,
then we have $\sigma h_1 = \sigma h_2$ for some permutations
$h_1, h_2 \in H$. But we can then compose $\sigma^{-1}$ to both of them
to get $h_1 = h_2$ which is not possible. Thus, $\sigma H$ has just as
many permutations as $H$. This also means that $h_2(x)$ has just as many
roots as $h(x)$.

We can repeat this process till we have covered all the permutations in
$G$, and equivalently, all the irreducible factors of $g(x)$. Each of
these factors would have the same degree. The sets $\sigma H$ are called
right-cosets of $H$. They all are of the same size. This shows that size
of $H$ divides the size of $G$. This process of dividing a group into
cosets of its subgroup can be carried for any group. In general, the
size of a subgroup always divides the size of the group.

# Factorization by Field Extension

So far, we have looked at the under the effect of factorization of the
resolvent polynomial. We found that Galois Group $H$ is a subgroup of
$G$. The size of $H$, which is equal to the degree of $h(x)$ divides the
size of $G$, which in turn is equal to the degree of $g(x)$.

In this section, we explore the factorization from the point of view of
the Field Extension. Suppose that we extend the field $K$ with an
element $r$ such that $r^p \in K$. We take $p$ to be a prime number. In
the example of the cubic solution from previous section, we can show
that the extension is using
$r = (r_1+\omega r_2+\omega^2 r_3)^3 - (r_1+\omega^2 r_2+\omega r_3)^3$
and that $r^2 \in K$. Another equivalent choices for $r$ is
$r = (r_1r_2^2 + r_2r_3^2 + r_3r_1^2) - (r_1^2r_2 + r_2^2r_3 + r_3^2r_1)$.

## Polynomial Factorization

Let $U(x)$ be a polynomial with coefficients in $K(r)$. Then, $U$ can
also be expressed as a polynomial with coefficients in $K$:

$$U(x, r) =  a_m(r) x^m +a_{m-1}(r) x^{m-1} +\ldots +a_2(r)x^2 +a_1(r)x +a_0(r)$$

If $V(x, r)$ is a factor of $U(x, r)$, then $U(x, r) = V(x, r)W(x, r)$

$$U(x, r) - V(x,r)W(x,r) =  b_m(r) x^m +b_{m-1}(r) x^{m-1} +\ldots +b_2(r)x^2 +b_1(r)x +b_0(r) = 0$$

$r$ is a root of $b_m(y)$, $b_{m-1}(y)$, $\ldots$, $b_2(y)$, $b_1(y)$,
$b_0(y)$. The irreducible polynomial of $r$ over $K$ is $y^p - r^p = 0$.
Thus, $y^p - r^p$ divides all of these polynomials. This means:

$$U(x, r) = V(x,r)W(x,r)$$

$$U(x, \alpha r) = V(x,\alpha r)W(x,\alpha r)$$

$$U(x, \alpha^2 r) = V(x,\alpha^2 r)W(x,\alpha^2 r)$$ $$\vdots$$

$$U(x, \alpha^{p-2} r) = V(x,\alpha^{p-2} r)W(x,\alpha^{p-2} r)$$

$$U(x, \alpha^{p-1} r) = V(x,\alpha^{p-1} r)W(x,\alpha^{p-1} r)$$

What we have shown is that if $V(x, r)$ divides $U(x, r)$, then
$V(x, \alpha^i r)$ divides $U(x, \alpha^i r)$.

## Factorization of Resolvent Polynomial

If $U(x, r) = g(x)$, and $h(x, r)$ is a factor of $U(x, r) = g(x)$, then
all of $h(x, \alpha^i r)$ are factors of $U(x, \alpha^i r) = g(x)$.
Thus, we can find $p$ different factors of $g$ from a single factor
$h(x, r)$:

$$g(x) = h(x,r)q(x,r)$$

$$g(x) = h(x,\alpha r)q(x,\alpha r)$$

$$g(x) = h(x,\alpha^2 r)q(x,\alpha^2 r)$$ $$\vdots$$

$$g(x) = h(x,\alpha^{p-1} r)q(x,\alpha^{p-1} r)$$

Multiplying these, we would get:

$$g(x)^p = H(x)Q(x)$$

where:

$$H(x) = h(x, r)h(x, \alpha r)h(x, \alpha^2 r) \ldots h(x, \alpha^{p-1} r)$$

This would imply:

$$g(x)^j = H(x) = h(x, r)h(x, \alpha r)h(x, \alpha^2 r) \ldots h(x, \alpha^{p-1} r)$$

There are $p$ irreducible factors on the right which when multiplied
give $g(x)^j$. From the previous section, we know that each of these
factors has a degree that divides the degree of $g(x)$. If deg($h(x)$) =
deg($g(x)$)/$m$, then $m$ factors on the right would be of the same
degree as $g(x)$ and $mj$ factors on the right side makes the total $p$
factors. This implies that $m$ divides $p$ or $m=1$ or $m=p$. Thus
deg($h(x)$) = deg($g(x)$)/$p$ or deg($h(x)$) = deg($g(x)$).

We have $p$ irreducible factors whose product is $g(x)^j$. From the
previous section, we know that degree of $h(x)$ divides degree of
$g(x)$. Let deg $h(x)$ = deg $g(x)/m$. Then, it takes exactly $m$ such
factors to match the degree of $g(x)$. However, the left side has $j$
copies of $g(x)$. It follows that the total number of irreducible
factors on the right must be $mj$. But, we know this to be $p$, which is
prime. Thus $m=1, j=p$ or $m=p,j=1$. This gives either deg $h(x)$ = deg
$g(x)$ implying $h(x) = g(x)$ or deg $h(x)$ = deg $g(x)/p$ implying:
$$g(x) = h(x, r)h(x, \alpha r)h(x, \alpha^2 r) \ldots h(x, \alpha^{p-1} r)$$

## Normal Subgroup

Let $t'$ be a root of $h(x,r)$. We know that $t'$ can be written as a
polynomial in $t$: $t' = \psi(t)$. Since $h(\psi(t),r) = 0$, we know
that $t$ is a root of $h(\psi(x),r)$. Thus $h(x,r)$ is a factor of
$h(\psi(x),r)$.

$h(x,r)$ being a factor of $h(\psi(x),r)$, implies that,
$h(x,\alpha^i r)$ is a factor of $h(\psi(x),\alpha^i r)$. Thus, if $u$
is a root of $h(x,\alpha^i r)$, so is $\psi(u)$.

The mapping $t \to \psi(t)$ can be represented using a permutation in
$H$. The permutation that maps $t \to u$ (say for $\sigma \in G$) also
maps $\psi(t) \to \psi(u)$. Thus, the mapping
$t \to \psi(t) \to \psi(u)$ can be seen as a permutation in $H$ followed
by some appropriate permutation in $G$. Thus, the permutation from $t$
to the roots of each factor can be represented as left-cosets $H\sigma$.

We already know that these same permutations can be presented as
right-cosets $\sigma H$. It is a rare occurence that right-cosets are
also left-cosets:

$$\sigma H = H\sigma$$

This relation holds true for
all $\sigma$. In other words for any $\sigma \in G$:

$$\sigma^{-1} H\sigma =H$$

Whenever, a subgroup follows this property,
we call it a Normal Subgroup.

# Solvability

So far, we have shown that, when we extend the field $K$ with a $r$ such
that $r^p \in K$, and the resolvent polynomial $g(s)$ can be further
factorized:

1.  $g(x)$ can be factored into $p$ factors of the form
    $h(x, \alpha^i r)$

2.  The Galois Group $H$ is a normal subgroup of $G$. Size of $H$ is
    $1/p$ times that of $G$.

The opposite of this statement is also true. Suppose we have a field $K$
and Galois Group $G$, that leaves $K$ fixed. If we know a normal
subgroup of $G$, say $H$ with size $1/p$, then there exists an element
$r$ such that $r^p \in K$, and Galois Group that leaves $K(r)$ fixed is
$N$. Before we prove this statement, we explore the consequences of
having a Normal Subgroup of size $1/p$ times the Group.

## Quotient Group

For any normal subgroup $H$ of $G$, the cosets form a group defined by:

$$(Ha) (Hb) = (Ha) (bH) = H(abH) = H(Hab) = Hab$$

This is represented by
the Quotient Group $G/H$. We observe that the Quotient Group is of size
$p$.

## Cyclic Subgroup

For any group $G$, and $\sigma \in G$, we can form the subgroup:

$$\{e, \sigma, \sigma^2,\ldots,\sigma^{k-1}\}$$

where $k$ is the
smallest number such that $\sigma^k = e$. This subgroup is called the
cyclic subgroup generated by $\sigma$ and has size $k$.

## Quotient Group is Cyclic

Let us consider a cyclic subgroup of the Quotient Group, generated by
some $\sigma \in G/H$. Let the size of the subgroup be $k$. Quotient
Group is of size $p$. So, $k$ divides $p$ implying $k=1$ or $k=p$. $k=1$
is not possible, since the subgroup has atleast two elements $e$ and
$\sigma$. $k=p$ implies that the entire group is the subgroup. This
means that the entire group ends up becoming cyclic, irrespective of the
choice of $\sigma$ (as long as, it is not the identity element).

For our purpose, let us represent the cosets as $H$, $\sigma H$,
$\sigma^2 H$, $\ldots$, $\sigma^{p-1} H$. As a consequence, any
permutation in $G$ can be represented as $\sigma^i h$, where $h \in H$.
We can equivalently define the quotient group $G/H$ as $\{e$, $\sigma$,
$\sigma^2$, $\ldots$, $\sigma^{p-1}\}$.

## Solvability

Here is a sketch of the proof of the converse statement, inspired from
Lagrange Resolvents. Given $H$, we can obtain all the corresponding $t\text{s}$
by composing the permutations in $H$ on $t$. Let these be $t_1$, $t_2$,
$\ldots$, $t_m$ with $mp = n$ where $n$ is the degree of $g$. We can
obtain the polynomial $h(x) = (x-t_1)(x-t_2)\ldots(x-t_m)$. The
coefficients of this polynomial cannot be in $K$, since the irreducible
polynomial containing $t$ is of degree $n = mp$. The coefficients of
this polynomial are candidates in $K(r)$. Let us choose one such
candidate and call it $\theta_1$.

Consider any permutation $\sigma$ from the quotient group $G/H$.
$\sigma$ fixes only elements of $K$, but not $K(r)$. $\sigma(\theta_1)$
cannot be $\theta_1$, since $\theta_1 \notin K$. Let
$\sigma(\theta_1) = \theta_2$, $\sigma^2(\theta_1) = \theta_3$ and so on
till $\sigma^{p-1}(\theta_1) = \theta_p$. Consider:

$$r_1 = \theta_1 + \alpha\theta_2 + \alpha^2\theta_3 + \ldots + \alpha^{p-1}\theta_p$$

$$r_2 = \theta_1 + \alpha^2\theta_2 + \alpha^4\theta_3 + \ldots + \alpha^{2(p-1)}\theta_p$$

$$r_3 = \theta_1 + \alpha^3\theta_2 + \alpha^6\theta_3 + \ldots + \alpha^{3(p-1)}\theta_p$$

$$\vdots$$

$$r_{p-1} = \theta_1 + \alpha^{p-1}\theta_2 + \alpha^{2(p-1)}\theta_3 + \ldots + \alpha^{(p-1)(p-1)}\theta_p$$

Atleast one of these has to be non-zero. If not, we can sum it all up to
get:

$$0 = p\theta_1 - \theta_1 - \theta_2 - \theta_3 \ldots - \theta_p$$

$$p\theta_1  = \theta_1 + \theta_2 + \theta_3 +\ldots + \theta_p$$

We could apply $\sigma$ on both sides to get:
$\theta_1 = \theta_2 = \ldots = \theta_p$, which is not true. Thus,
without loss of generality we can assume that the following is non-zero:

$$r = \theta_1 + \alpha\theta_2 + \alpha^2\theta_3 + \ldots + \alpha^{p-2}\theta_{p-1} + \alpha^{p-1}\theta_p$$

Applying $\sigma$ on both sides:

$$\sigma(r) = \theta_2 + \alpha\theta_3 + \alpha^2\theta_4 + \ldots + \alpha^{p-2}\theta_{p} + \alpha^{p-1}\theta_1 = r/\alpha$$

This gives $\sigma(r^p) = r^p$.

Any permutation in $G$, is of the form $\sigma^i h$ for some $h \in H$.

$$\sigma^i(h(r)) = \sigma^i(r) = r/\alpha^i$$

since $h$ does not affect
$\theta_i\text{s}$. Hence:

$$\sigma^i(h(r^p)) = (r/\alpha^i)^p = r^p$$

$r^p$ is
fixed by all permutations in $G$, implying that $r^p \in K$.

We have shown that the process of solving a polynomial by radicals can
be understood entirely through the structure of its Galois group. Each
time the base field $K$ is extended by adjoining an element $r$ with
$r^p \in K$, the corresponding resolvent polynomial factors in a highly
structured way, and the Galois group shrinks to a normal subgroup of
size $1/p$ of the original Galois Group. Conversely, the existence of a
normal subgroup guarantees the existence of a field extension obtained
by adjoining a $p^{th}$ root. Following this trail of Galois Groups from
that of the original polynomial to a group of only identity element, we
can derive a way to solve the polynomial using basic algebraic
operations and radicals.
